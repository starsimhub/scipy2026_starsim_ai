# SciPy 2026: Starsim AI Evaluation

## Introduction

Submission for [SciPy 2026](https://pretalx.com/scipy-2026/cfp) evaluating Starsim-AI.

Deadline: **February 25, 2026**
Targeting track: **Data-Driven Discovery, Machine Learning and Artificial Intelligence**

This track aims to bring together the latest advances in Artificial Intelligence and Machine Learning (AI/ML) and areas of data-driven insights that focus on advancing novel discovery across fields and applications in science and industry. This includes the development and application of new and existing open-source tools and techniques that have been influential in advancing scientific progress. **We encourage submissions that include stories of applications and improvements to simulation and simulation-based inference.**

## Proposal

- Build a Claude Code plugin for Starsim that combines MCP servers for Starsim + individual models and general skills (e.g., a disease modeling expert subagent, a code quality subagent)
- Write an exam to test Starsim skills/knowledge
- Evaluate how well the enhanced AI performs compared to out-of-the-box versions on the exam

## Talk plan
- Intro to the problem (getting up to speed on a complex library) and Starsim
- How we developed the Starsim exam, and what worked well and didn't
- Describe which skills/subagents we developed and why
- Models and skillsets we tested
- Evaluation of each combination
- Open-source "gym" for users to plug in their own library, skills, and exam